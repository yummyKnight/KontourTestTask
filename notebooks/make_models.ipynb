{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TODO:\n",
    "* sklearn text\n",
    "* spaCy\n",
    "* transformers\n",
    "* Anomaly detection in NLP\n",
    "### 19.04\n",
    "* Бейзлайн за 2 часа\n",
    "* Полный pipeline для обучения за 2 часа\n",
    "* Ресерч техник, нейронки\n",
    "* Исследовать метрику (чем плоха f1)\n",
    "####\n",
    "Умные мысли\n",
    "* насколько числа играют важную роль?\n",
    "* играет ли роль стемминг?\n",
    "* играет ли роль нормализация?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../dataset/train.tsv\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(\"../dataset/train.tsv\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprcessing\n",
    "## TODO:\n",
    "* lower()\n",
    "* remove punkt\n",
    "* change digits to words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from num2words import num2words\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('russian')\n",
    "    ext_punt = string.punctuation + \"«\" + \"»\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in ext_punt]\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    tokens = []\n",
    "    for token in nopunc.split(\" \"):\n",
    "        value = token\n",
    "        try:\n",
    "            value = int(token)\n",
    "            value = num2words(value, lang='ru')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        finally:\n",
    "            tokens.append(value)\n",
    "\n",
    "    nopunc = \" \".join(tokens)\n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_df['clean_title'] = train_df['title'].apply(text_process)\n",
    "# есть ли смысл убирать римские цифры и тд?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0       Москвичу Владимиру Клутину пришёл счёт вмешате...\n1       Агент Кокорина назвал езду встречке житейской ...\n2       Госдума рассмотрит возможность введения секрет...\n3       ФАС заблокировала поставку скоростных трамваев...\n4       Против Навального завели дело недоносительстве...\n                              ...                        \n5753     Эдди Чемберс получил сотрясение мозга бою Кличко\n5754    Правительство застроит Россию нефтепродуктопро...\n5755    стыдно дедом новый канцлер ФРГ обратился перво...\n5756         Туркмения декабре начнет поставки газа Китай\n5757    Бывший тренер Локомотива возглавил нальчикский...\nName: clean_title, Length: 5758, dtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean_title']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "pipe1 = Pipeline([('bow', CountVectorizer()),\n",
    "                 ('tfid', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "pipe2 = Pipeline([('bow', CountVectorizer()),\n",
    "                 ('tfid', TfidfTransformer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "pipe3 = Pipeline([('tfid', TfidfVectorizer(strip_accents='unicode', ngram_range=(1, 2))),\n",
    "                 # ('tfid', ),\n",
    "                 ('model', MultinomialNB())])\n",
    "\n",
    "# Vectorizer(Count, tfidf, both), model(Bayes, SVD, LogReg, word2vec*, nn*), * different preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.829     , 0.82965932, 0.82875686])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(pipe1, train_df['clean_title'], train_df['is_fake'], cv=cv, n_jobs=-1, scoring='f1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.81558442, 0.81515617, 0.81295716])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(pipe2, train_df['clean_title'], train_df['is_fake'], cv=cv, n_jobs=-1, scoring='f1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.82934132, 0.83009467, 0.82194514])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(pipe3, train_df['clean_title'], train_df['is_fake'], cv=cv, n_jobs=-1, scoring='f1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}