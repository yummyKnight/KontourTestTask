{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TODO:\n",
    "* sklearn text\n",
    "* spaCy\n",
    "* transformers\n",
    "* Anomaly detection in NLP\n",
    "### 19.04\n",
    "* Бейзлайн за 2 часа\n",
    "* Полный pipeline для обучения за 2 часа\n",
    "* Ресерч техник, нейронки\n",
    "* Исследовать метрику (чем плоха f1)\n",
    "####\n",
    "Умные мысли\n",
    "* насколько числа играют важную роль?\n",
    "* играет ли роль стемминг?\n",
    "* играет ли роль нормализация?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../dataset/train.tsv\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(\"../dataset/train.tsv\", sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprcessing\n",
    "## TODO:\n",
    "* lower()\n",
    "* remove punkt\n",
    "* change digits to words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from num2words import num2words\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    STOPWORDS = stopwords.words('russian')\n",
    "    ext_punt = string.punctuation + \"«\" + \"»\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in ext_punt]\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    tokens = []\n",
    "    for token in nopunc.split(\" \"):\n",
    "        value = token\n",
    "        try:\n",
    "            value = int(token)\n",
    "            value = num2words(value, lang='ru')\n",
    "        except ValueError:\n",
    "            pass\n",
    "        finally:\n",
    "            tokens.append(value)\n",
    "\n",
    "    nopunc = \" \".join(tokens)\n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_df['clean_title'] = train_df['title'].apply(text_process)\n",
    "# есть ли смысл убирать римские цифры и тд?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0       Москвичу Владимиру Клутину пришёл счёт вмешате...\n1       Агент Кокорина назвал езду встречке житейской ...\n2       Госдума рассмотрит возможность введения секрет...\n3       ФАС заблокировала поставку скоростных трамваев...\n4       Против Навального завели дело недоносительстве...\n                              ...                        \n5753     Эдди Чемберс получил сотрясение мозга бою Кличко\n5754    Правительство застроит Россию нефтепродуктопро...\n5755    стыдно дедом новый канцлер ФРГ обратился перво...\n5756         Туркмения декабре начнет поставки газа Китай\n5757    Бывший тренер Локомотива возглавил нальчикский...\nName: clean_title, Length: 5758, dtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['clean_title']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "pipe1 = Pipeline([('bow', CountVectorizer()),\n",
    "                 ('tfid', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "pipe2 = Pipeline([('bow', CountVectorizer()),\n",
    "                 ('tfid', TfidfTransformer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "pipe3 = Pipeline([('tfid', TfidfVectorizer(strip_accents='unicode', ngram_range=(1, 2))),\n",
    "                 # ('tfid', ),\n",
    "                 ('model', MultinomialNB())])\n",
    "# Vectorizer(Count, tfidf, both), model(Bayes, SVD, LogReg, word2vec*, nn*), * different preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.829     , 0.82965932, 0.82875686])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(pipe1, train_df['clean_title'], train_df['is_fake'], cv=cv, n_jobs=-1, scoring='f1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.81558442, 0.81515617, 0.81295716])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(pipe2, train_df['clean_title'], train_df['is_fake'], cv=cv, n_jobs=-1, scoring='f1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# perform cross validation with metrics\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "def perform_fit(pipe : Pipeline, data : pd.Series, target : pd.Series):\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    for fold, (train_ids, valid_ids) in enumerate(kfold.split(data, target)):\n",
    "        pipe.fit(data.loc[train_ids], target.loc[train_ids])\n",
    "        y_true = target.loc[valid_ids]\n",
    "        preds = pipe.predict(data.loc[valid_ids])\n",
    "        print(f\"Classification report for fold - {fold}\")\n",
    "        print(\"F1 score - \", round(f1_score(y_true, preds), 4))\n",
    "        print(\"Conf matrix:\")\n",
    "        print(confusion_matrix(y_true, preds))\n",
    "        # print(classification_report(, preds, target_names=['not fake', 'fake']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test vectorization\n",
    "https://andhint.github.io/machine-learning/nlp/Feature-Extraction-From-Text/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold - 0\n",
      "F1 score -  0.8289\n",
      "Conf matrix:\n",
      "[[746 214]\n",
      " [129 831]]\n",
      "Classification report for fold - 1\n",
      "F1 score -  0.8265\n",
      "Conf matrix:\n",
      "[[742 217]\n",
      " [131 829]]\n",
      "Classification report for fold - 2\n",
      "F1 score -  0.8287\n",
      "Conf matrix:\n",
      "[[743 217]\n",
      " [127 832]]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('bow', CountVectorizer()),\n",
    "                 # ('tfid', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "perform_fit(pipe, train_df['clean_title'], train_df['is_fake'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.829):\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([('bow', CountVectorizer()),\n",
    "                 # ('tfid', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "param_grid = {\n",
    "    \"bow__ngram_range\": [(1, 1), (1, 2), (1, 3), (2, 3)],\n",
    "    \"bow__max_df\": [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 1.0],\n",
    "    \"bow__min_df\": [2, 3, 4, 1],\n",
    "    # \"bow__max_features\": [2, 3, 4],\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, cv=cv, scoring='f1' ,n_jobs=-1)\n",
    "search.fit(train_df['clean_title'], train_df['is_fake'])\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "# вывод по max_df - очень малое кол-во слов отличает fake от не fake"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.830):\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([('bow', CountVectorizer()),\n",
    "                 ('tfid', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "param_grid = {\n",
    "    \"bow__ngram_range\": [(1, 1), (1, 2), (1, 3), (2, 3)],\n",
    "    \"bow__max_df\": [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 1.0],\n",
    "    \"bow__min_df\": [2, 3, 4, 1],\n",
    "    # \"bow__max_features\": [2, 3, 4],\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, cv=cv, scoring='f1' ,n_jobs=-1)\n",
    "search.fit(train_df['clean_title'], train_df['is_fake'])\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for fold - 0\n",
      "F1 score -  0.8332\n",
      "Conf matrix:\n",
      "[[755 205]\n",
      " [128 832]]\n",
      "False positive\n"
     ]
    },
    {
     "data": {
      "text/plain": "14            Режиссера Алексея Германа наградили орденом\n35       U2 Metallica сыграют юбилее Зала славы рокнролла\n81            Польше готовятся издать поэму Папы Римского\n83      Олимпийские винтовки Бьорндалена ошибке отправ...\n158     Правительство России дорого заплатит федеральн...\n                              ...                        \n5708    Шарон Стоун Джо Пеши сыграли самую худшую любо...\n5712     Сотрудники МВД пришли документами Росстрахнадзор\n5732                Вдова Джорджа Харрисона посвятила сад\n5733    Силуанов пересчитал оставшиеся резервах России...\n5754    Правительство застроит Россию нефтепродуктопро...\nName: clean_title, Length: 205, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negative\n"
     ]
    },
    {
     "data": {
      "text/plain": "30      Ольгино объяснили большое количество комментар...\n75      Минэнерго ФРГ выпустило обучающие ролики пошив...\n113                   Domestos разработает свой антивирус\n145     известной картине Леонардо Винчи обнаружили QRкод\n146     “Дальше Божьей помощью” Москве мужчину пустили...\n                              ...                        \n5531    Автором экстремистского произведения Протоколы...\n5601    приема беженцев Литве восстановлена инфраcтрук...\n5611     Великобритании начали разыгрывать бензин лотерею\n5742    Газпром Минцифры запускают конкурс самый зрели...\n5755    стыдно дедом новый канцлер ФРГ обратился перво...\nName: clean_title, Length: 128, dtype: object"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from IPython.core.display_functions import display\n",
    "\n",
    "pipe = Pipeline([('bow', CountVectorizer(max_df=0.1, ngram_range=(1, 3))),\n",
    "                 ('tfid', TfidfTransformer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "data = train_df['clean_title']\n",
    "target = train_df['is_fake']\n",
    "for fold, (train_ids, valid_ids) in enumerate(cv.split(data, target)):\n",
    "    pipe.fit(data.loc[train_ids], target.loc[train_ids])\n",
    "    y_true = target.loc[valid_ids]\n",
    "    test = data.loc[valid_ids]\n",
    "    preds = pipe.predict(test)\n",
    "    print(f\"Classification report for fold - {fold}\")\n",
    "    print(\"F1 score - \", round(f1_score(y_true, preds), 4))\n",
    "    print(\"Conf matrix:\")\n",
    "    print(confusion_matrix(y_true, preds))\n",
    "    print(\"False positive\")\n",
    "    display(test[preds > y_true])\n",
    "    print(\"False negative\")\n",
    "    display(test[preds < y_true])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "class VecTfidfTransformer(CountVectorizer):\n",
    "    def __init__(self, *, input=\"content\", encoding=\"utf-8\", decode_error=\"strict\", strip_accents=None, lowercase=True,\n",
    "                 preprocessor=None, tokenizer=None, stop_words=None, token_pattern=r\"(?u)\\b\\w\\w+\\b\", ngram_range=(1, 1),\n",
    "                 analyzer=\"word\", max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False,\n",
    "                 dtype=np.int64):\n",
    "      self.s = super().__init__(input=input, encoding=encoding, decode_error=decode_error, strip_accents=strip_accents,\n",
    "                       lowercase=lowercase, preprocessor=preprocessor, tokenizer=tokenizer, stop_words=stop_words,\n",
    "                       token_pattern=token_pattern, ngram_range=ngram_range, analyzer=analyzer, max_df=max_df,\n",
    "                       min_df=min_df, max_features=max_features, vocabulary=vocabulary, binary=binary, dtype=dtype)\n",
    "      self.tf_idf = TfidfTransformer()\n",
    "    def fit(self, X, y=None):\n",
    "        self.tf_idf.fit(self.s.fit_transform(X))\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        vectorized = self.s.transform(X)\n",
    "        count_vectorized = self.tf_idf.transform(vectorized)\n",
    "        return scipy.sparse.hstack([vectorized, count_vectorized])\n",
    "\n",
    "    def __repr__(self, N_CHAR_MAX=700):\n",
    "        return \"VectTfidf with params\" + self.s.__repr__()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing pipe - Pipeline(steps=[('bow', CountVectorizer()), ('nb', MultinomialNB())])\n",
      "{'bow__ngram_range': [(1, 1), (1, 2), (1, 3)], 'bow__max_df': [0.1, 0.2, 0.5, 1.0], 'bow__min_df': [1], 'nb__alpha': [1.0, 1.2, 1.5, 2.0, 3.0, 4.0]}\n",
      "Best parameter (CV score=0.831): +- 0.002280398322083378\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 3), 'nb__alpha': 2.0}\n",
      "Time -  10.677000284194946\n",
      "Testing pipe - Pipeline(steps=[('bow', CountVectorizer()), ('lr', LogisticRegression())])\n",
      "{'bow__ngram_range': [(1, 1), (1, 2), (1, 3)], 'bow__max_df': [0.1, 0.2, 0.5, 1.0], 'bow__min_df': [1], 'lr__penalty': ['l1', 'l2'], 'lr__solver': ['liblinear'], 'lr__C': [0.01, 0.021544346900318832, 0.046415888336127774, 0.1, 0.21544346900318834, 0.46415888336127775, 1.0, 2.154434690031882, 4.6415888336127775, 10.0], 'lr__random_state': [42]}\n",
      "Best parameter (CV score=0.798): +- 0.24760559251926617\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 1), 'lr__C': 2.154434690031882, 'lr__penalty': 'l2', 'lr__random_state': 42, 'lr__solver': 'liblinear'}\n",
      "Time -  35.15798807144165\n",
      "Testing pipe - Pipeline(steps=[('bow', CountVectorizer()), ('svc', SVC())])\n",
      "{'bow__ngram_range': [(1, 1), (1, 2), (1, 3)], 'bow__max_df': [0.1, 0.2, 0.5, 1.0], 'bow__min_df': [1], 'svc__C': [0.01, 0.021544346900318832, 0.046415888336127774, 0.1, 0.21544346900318834, 0.46415888336127775, 1.0, 2.154434690031882, 4.6415888336127775, 10.0], 'svc__kernel': ['linear', 'poly', 'sigmoid'], 'svc__degree': [2, 3]}\n",
      "Best parameter (CV score=0.807): +- 0.2902100774478706\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 1), 'svc__C': 2.154434690031882, 'svc__degree': 2, 'svc__kernel': 'sigmoid'}\n",
      "Time -  491.83053398132324\n",
      "Testing pipe - Pipeline(steps=[('bow', TfidfVectorizer()), ('nb', MultinomialNB())])\n",
      "{'bow__ngram_range': [(1, 1), (1, 2), (1, 3)], 'bow__max_df': [0.1, 0.2, 0.5, 1.0], 'bow__min_df': [1], 'nb__alpha': [1.0, 1.2, 1.5, 2.0, 3.0, 4.0]}\n",
      "Best parameter (CV score=0.831): +- 0.00220576767158481\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 2), 'nb__alpha': 1.5}\n",
      "Time -  6.98901104927063\n",
      "Testing pipe - Pipeline(steps=[('bow', TfidfVectorizer()), ('lr', LogisticRegression())])\n",
      "{'bow__ngram_range': [(1, 1), (1, 2), (1, 3)], 'bow__max_df': [0.1, 0.2, 0.5, 1.0], 'bow__min_df': [1], 'lr__penalty': ['l1', 'l2'], 'lr__solver': ['liblinear'], 'lr__C': [0.01, 0.021544346900318832, 0.046415888336127774, 0.1, 0.21544346900318834, 0.46415888336127775, 1.0, 2.154434690031882, 4.6415888336127775, 10.0], 'lr__random_state': [42]}\n",
      "Best parameter (CV score=0.826): +- 0.3398659518397094\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 3), 'lr__C': 10.0, 'lr__penalty': 'l2', 'lr__random_state': 42, 'lr__solver': 'liblinear'}\n",
      "Time -  106.13098549842834\n",
      "Testing pipe - Pipeline(steps=[('bow', TfidfVectorizer()), ('svc', SVC())])\n",
      "{'bow__ngram_range': [(1, 1), (1, 2), (1, 3)], 'bow__max_df': [0.1, 0.2, 0.5, 1.0], 'bow__min_df': [1], 'svc__C': [0.01, 0.021544346900318832, 0.046415888336127774, 0.1, 0.21544346900318834, 0.46415888336127775, 1.0, 2.154434690031882, 4.6415888336127775, 10.0], 'svc__kernel': ['linear', 'poly', 'sigmoid'], 'svc__degree': [2, 3]}\n",
      "Best parameter (CV score=0.830): +- 0.17041179519847505\n",
      "{'bow__max_df': 0.1, 'bow__min_df': 1, 'bow__ngram_range': (1, 2), 'svc__C': 1.0, 'svc__degree': 2, 'svc__kernel': 'linear'}\n",
      "Time -  486.7230136394501\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "pipe_bow = [(\"bow\", CountVectorizer()), (\"bow\", TfidfVectorizer())]\n",
    "bow_param_grid = {\n",
    "    \"bow__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    # \"bow__ngram_range\": [(1, 1), (1, 2), (1, 3), (2, 3)],\n",
    "    \"bow__max_df\": [0.1, 0.2, 0.5, 1.0],\n",
    "    # \"bow__max_df\": [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 1.0],\n",
    "    # \"bow__min_df\": [2, 3, 4, 1],\n",
    "    \"bow__min_df\": [1],\n",
    "    # \"bow__max_features\": [2, 3, 4],\n",
    "}\n",
    "pipe_classifier = [('nb', MultinomialNB()), ('lr', LogisticRegression()), ('svc', SVC())]\n",
    "class_grid = {\n",
    "    'nb' : {\n",
    "        \"nb__alpha\" : [1., 1.2, 1.5, 2., 3., 4.]\n",
    "    },\n",
    "    'lr': {\n",
    "        \"lr__penalty\" : ['l1', 'l2'],\n",
    "        \"lr__solver\" : ['liblinear'],\n",
    "        # \"lr__max_iter\" : [100, 200, 300],\n",
    "        \"lr__C\" : list(np.logspace(-2, 1, num=10)),\n",
    "        \"lr__random_state\" : [42],\n",
    "    },\n",
    "    'svc': {\n",
    "        \"svc__C\" : list(np.logspace(-2, 1, num=10)),\n",
    "        \"svc__kernel\" : ['linear', 'poly', 'sigmoid'],\n",
    "        \"svc__degree\" : [2, 3],\n",
    "    }\n",
    "}\n",
    "searches = []\n",
    "for bow in pipe_bow:\n",
    "    for cls_ in pipe_classifier:\n",
    "        pipe = Pipeline([bow, cls_])\n",
    "        param_grid = {**bow_param_grid , **class_grid[cls_[0]]}\n",
    "        print(f\"Testing pipe - {pipe}\")\n",
    "        print(param_grid)\n",
    "        search = GridSearchCV(pipe, param_grid, cv=cv, scoring='f1' ,n_jobs=-1)\n",
    "        start = time.time()\n",
    "        search.fit(train_df['clean_title'], train_df['is_fake'])\n",
    "        print(f\"Best parameter (CV score={search.best_score_:.3f}): +- {np.std(search.cv_results_['mean_test_score'])}\")\n",
    "        print(search.best_params_)\n",
    "        print(\"Time - \", time.time() - start)\n",
    "        searches.append(search)\n",
    "\n",
    "with open(\"searches.pkl\", 'wb') as f:\n",
    "    pickle.dump(searches, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=nan): +- nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W:\\Work\\Anaconda\\envs\\TORCHGPU\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"bow\", VecTfidfTransformer()), ('lr', LogisticRegression())])\n",
    "param_grid = {\"lr__penalty\": ['l1', 'l2'],\n",
    " \"lr__solver\": ['liblinear'],\n",
    " # \"lr__max_iter\" : [100, 200, 300],\n",
    " \"lr__C\": list(np.logspace(-2, 1, num=10)),\n",
    " \"lr__random_state\": [42],\n",
    " }\n",
    "search = GridSearchCV(pipe, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "start = time.time()\n",
    "search.fit(train_df['clean_title'], train_df['is_fake'])\n",
    "print(f\"Best parameter (CV score={search.best_score_:.3f}): +- {np.std(search.cv_results_['mean_test_score'])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8615)\t1\n",
      "  (0, 2653)\t1\n",
      "  (0, 6723)\t1\n",
      "  (0, 12805)\t1\n",
      "  (0, 15919)\t1\n",
      "  (0, 2677)\t1\n",
      "  (0, 1113)\t1\n",
      "  (0, 3120)\t1\n",
      "  (1, 921)\t1\n",
      "  (1, 6773)\t1\n",
      "  (1, 8852)\t1\n",
      "  (1, 4946)\t1\n",
      "  (1, 3052)\t1\n",
      "  (1, 5094)\t1\n",
      "  (1, 6219)\t1\n",
      "  (2, 3804)\t1\n",
      "  (2, 13607)\t1\n",
      "  (2, 2809)\t1\n",
      "  (2, 2323)\t1\n",
      "  (2, 14571)\t1\n",
      "  (2, 15632)\t1\n",
      "  (2, 16692)\t1\n",
      "  (2, 6764)\t1\n",
      "  (3, 17173)\t1\n",
      "  (3, 5144)\t1\n",
      "  :\t:\n",
      "  (5754, 12283)\t1\n",
      "  (5754, 14061)\t1\n",
      "  (5754, 5536)\t1\n",
      "  (5754, 9396)\t1\n",
      "  (5755, 17405)\t1\n",
      "  (5755, 6411)\t1\n",
      "  (5755, 9520)\t1\n",
      "  (5755, 9761)\t1\n",
      "  (5755, 10947)\t1\n",
      "  (5755, 15792)\t1\n",
      "  (5755, 4198)\t1\n",
      "  (5755, 13871)\t1\n",
      "  (5755, 2143)\t1\n",
      "  (5756, 3438)\t1\n",
      "  (5756, 9129)\t1\n",
      "  (5756, 6651)\t1\n",
      "  (5756, 12098)\t1\n",
      "  (5756, 4208)\t1\n",
      "  (5756, 16568)\t1\n",
      "  (5757, 2177)\t1\n",
      "  (5757, 16427)\t1\n",
      "  (5757, 2783)\t1\n",
      "  (5757, 15381)\t1\n",
      "  (5757, 7723)\t1\n",
      "  (5757, 8933)\t1\n"
     ]
    }
   ],
   "source": [
    "print(VecTfidfTransformer().fit_transform(train_df['clean_title']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}